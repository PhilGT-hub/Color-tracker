<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Object Tracker with Camera Flip</title>
<style>
  body { font-family: sans-serif; text-align: center; background: #f0f0f0; padding: 20px; }
  video, canvas { border: 1px solid #333; margin-top: 10px; }
  #controls { margin: 10px; }
</style>
</head>
<body>
<h1>Object Tracker with Camera Flip</h1>
<div id="controls">
  <button id="screenshotBtn">Screen Shot</button>
  <button id="applyBtn">Apply Tracking</button>
  <button id="flipBtn">Flip Camera</button>
</div>

<video id="video" autoplay playsinline width="320" height="240"></video>
<canvas id="canvas" width="320" height="240"></canvas>

<script>
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');

let templateData = null;
let templateRect = null;
let isSelecting = false;
let startX = 0, startY = 0;
let currentFacingMode = "environment"; // start with back camera
let stream = null;

// Helper: stop current camera
function stopStream() {
    if(stream){
        stream.getTracks().forEach(track => track.stop());
    }
}

// Start camera with specific facingMode
async function startCamera(facingMode) {
    stopStream();
    try {
        stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: facingMode }
        });
        video.srcObject = stream;
    } catch(err){
        alert("Camera error: " + err);
    }
}

// Initialize camera
startCamera(currentFacingMode);

// Mouse events for drawing selection rectangle
canvas.addEventListener('mousedown', e => {
    if(!templateData) return;
    isSelecting = true;
    const rect = canvas.getBoundingClientRect();
    startX = e.clientX - rect.left;
    startY = e.clientY - rect.top;
});
canvas.addEventListener('mousemove', e => {
    if(!isSelecting) return;
    const rect = canvas.getBoundingClientRect();
    const mouseX = e.clientX - rect.left;
    const mouseY = e.clientY - rect.top;
    const w = mouseX - startX;
    const h = mouseY - startY;
    ctx.putImageData(templateData,0,0);
    ctx.strokeStyle = 'red';
    ctx.lineWidth = 2;
    ctx.strokeRect(startX,startY,w,h);
});
canvas.addEventListener('mouseup', e => {
    if(!isSelecting) return;
    const rect = canvas.getBoundingClientRect();
    const endX = e.clientX - rect.left;
    const endY = e.clientY - rect.top;
    templateRect = {
        x: Math.min(startX,endX),
        y: Math.min(startY,endY),
        w: Math.abs(endX-startX),
        h: Math.abs(endY-startY)
    };
    isSelecting = false;
});

// Screenshot
document.getElementById('screenshotBtn').addEventListener('click', () => {
    ctx.drawImage(video,0,0,canvas.width,canvas.height);
    templateData = ctx.getImageData(0,0,canvas.width,canvas.height);
    templateRect = null;
});

// Apply tracking (template matching)
function applyTracking() {
    if(!templateRect){ alert('Draw a rectangle on screenshot first'); return; }
    const t = ctx.getImageData(templateRect.x, templateRect.y, templateRect.w, templateRect.h);

    function matchFrame() {
        ctx.drawImage(video,0,0,canvas.width,canvas.height);
        const frame = ctx.getImageData(0,0,canvas.width,canvas.height);
        let bestDiff = Infinity;
        let bestX=0, bestY=0;

        for(let y=0; y <= frame.height - t.height; y+=2){
            for(let x=0; x <= frame.width - t.width; x+=2){
                let diff = 0;
                for(let ty=0; ty<t.height; ty+=2){
                    for(let tx=0; tx<t.width; tx+=2){
                        const fi = ((y+ty)*frame.width + (x+tx))*4;
                        const ti = (ty*t.width + tx)*4;
                        diff += Math.abs(frame.data[fi]-t.data[ti]);
                        diff += Math.abs(frame.data[fi+1]-t.data[ti+1]);
                        diff += Math.abs(frame.data[fi+2]-t.data[ti+2]);
                    }
                }
                if(diff < bestDiff){
                    bestDiff = diff;
                    bestX = x;
                    bestY = y;
                }
            }
        }

        ctx.strokeStyle = 'lime';
        ctx.lineWidth = 2;
        ctx.strokeRect(bestX,bestY,t.width,t.height);

        requestAnimationFrame(matchFrame);
    }
    matchFrame();
}

// Flip camera
document.getElementById('flipBtn').addEventListener('click', () => {
    currentFacingMode = (currentFacingMode === "environment") ? "user" : "environment";
    startCamera(currentFacingMode);
});

document.getElementById('applyBtn').addEventListener('click', applyTracking);
</script>
</body>
</html>
